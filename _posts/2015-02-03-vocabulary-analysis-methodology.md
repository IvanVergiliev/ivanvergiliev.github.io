---
layout: post
title: "Историята на едно необичайно литературно изследване"
modified:
categories: 
excerpt: "Или как, и защо точно така, преброихме уникалните думи на Вазов"
tags: []
image:
  feature:
date: 2015-02-03T02:38:28+02:00
---

<script type="text/javascript" src="/assets/js/vendor/Chart.min.js"></script>

<div class="fb-like" data-href="http://ivanvergiliev.github.io/vocabulary-analysis-methodology/"
  data-layout="standard" data-action="like" data-show-faces="true" data-share="true">
</div>

{% include vocab_unique.json %}

В [предишната статия](http://ivanvergiliev.github.io/vocabulary-analysis/) анализирахме лексиката на някои български автори. След това отхвърлихме идеята за сравнението между английски и български творци. В тази ще обсъдим методологията на самото изследване и компромисите, които помогнаха за осъществяването му.

Ще започнем с кратко резюме на получените резултати. Разгледахме **първите 200 000 думи** от произведенията на няколко автора. След това преброихме колко различни думи се срещат в тези 200 000, използвайки проста и ясна дефиниция - **две думи са различни, ако се различават  в изписването си.** Така *маса* и *маси* се броят за две думи, въпреки че основната им форма е една и съща. Съответно две думи се смятат за еднакви, ако се изписват по един и същ начин - *маса* от изразите “кухненска маса” и “маса на атома” ще се преброи веднъж, въпреки че смисълът е различен. Накрая сравнихме броя уникални думи на авторите, и донякъде затвърдихме тезата, че Вазов е имал най-богат речников състав.

Защо обаче разглеждаме точно първите N думи, а не всичките? Защо използваме точно това определение за различни и еднакви думи? Тези въпроси ще разгледаме в настоящата статия.

Думите ***маси*** и ***масата*** са част от една и съща **лексема** - или множество думи с еднакво значение и разлика само във формата. Употребата и на двата варианта не обогатява речника на използващия ги - така че защо не ги преброим само веднъж? За целта трябва да ги **нормализираме** и от формата *масата* да получим основната форма (или **лема**) - *маса*. За съжаление, този процес е труден за автоматизиране - в българския език няма строги, винаги валидни правила за образуване на различните форми. Например думите *кот**ка*** и *ръ**ка*** изглеждат сходни - и двете са в женски род и завършват по един и същ начин, но формите им за множествено число значително се различават - *кот**ки*** и *ръ**це***.

Традиционният подход за нормализация е ръчен - човек чете текста и записва
основната форма на всяка следваща дума. Главното предимство на този метод е, че
хората извършват тази задача със сравнителна лекота - особено ако търсим
уникалните думи в един разказ например.  Когато става въпрос за милиони думи
обаче, такова начинание би отнело твърде много време. Освен това, ако
извършваме подобно, но не напълно еднакво действие многократно, ще започнем да
правим все повече грешки. Читателите с повече свободно време могат да направят
експеримент и да съберат 10 000 двойки многоцифрени числа - след което да
повторят операцията и да проверят дали ще получат същите резултати.

Поради такива причини хората, занимаващи се с компютърна лингвистика и
обработка на естествен език, са създали различни алгоритми за автоматично
определяне на основната форма на дума. Тъй като са автоматични, те могат да се
използват за големи количества данни. Двата основни варианта носят звучните
имена **лематизация** и **стеминг**. Граница между тях е малко размита, но тук
ще изясним основните им характеристики.

Лематизацията е по-точен, но по-бавен подход, в който обикновено се използва речник от различните
форми на дадена дума към основната - например (*маси → маса*), (*масите → маса*) и т.н. След това
се определят допълнителни детайли за разглежданата дума с цел по-голяма
точност. Например само от думата *казана* не знаем дали това е членуваната форма
на *съд за варене на алкохолни напитки*, или част от народната мъдрост “Казана дума, хвърлен
камък”. Ако обаче знаем, че *казана* е прилагателно име от женски род, решението е по-лесно.
(Такава информация можем да получим от алгоритми за определяне частите на речта,
или [part-of-speech tagging](http://en.wikipedia.org/wiki/Part-of-speech_tagging).)
Основният проблем е, че езикът е динамичен и се променя постоянно, ала речникът е статичен
- един речник, съставен през 2015 година, не може да съдържа думите, които младежите през 2080-та
ще използват, нито тези, които Иван Вазов и Елин Пелин са използвали в началото на XX-ти век.
Освен това, алгоритмите за определяне частите на речта са сложни за създаване, и може да не са
напълно точни, което също влияе на качеството на лематизацията.

Стемингът е по-бърз и неточен метод, който използва конкретни характеристики на езика. Обикновено се състои от правила за премахване на наставки - тип “Ако думата завършва на **-ът**, основната форма се получава, като **-ът** се премахне” (**мъжът → мъж**, но ако правилото е толкова просто, може да доведе и до грешки - например **път → п**). Освен това при този подход не се получава истинската основна форма на думата, а така нареченият стем. Например от правилото “Ако думата завършва на **-ият**, премахваме **-ият**” и думата **големият** ще получим стема **голем**, вместо основната форма **голям**.

На следващата графика ще покажем броя уникални леми в първите 200 000 думи на авторите, използвайки готов [алгоритъм за лематизация](https://github.com/Glamdring/language-tools-bg/blob/master/src/main/java/bg/bozho/ikratko/other/NewsSitesVocabulary.java). Алгоритъмът използва речник от двойки (**дума → основна форма**), но не използва допълнителна информация - например не се определя каква част на речта е всяка от думите. Освен това, ако някоя дума не е в речника, тя се игнорира напълно - така думата **пивопийци**, използвана от Вазов, няма да се преброи, защото не е част от един съвременен речник.

<canvas id="lemmasIgnoreMissing" width="550" height="400"></canvas>
<script type="text/javascript">
  var lemmasIgnoreMissingCtx = document.getElementById('lemmasIgnoreMissing').getContext('2d');
  var options = {
    scaleLabel: " <%= value %>",
    scaleShowVerticalLines: false,
    barValueSpacing: 10,
    scaleFontStyle: 'bold',
    scaleFontSize: 14,
    scaleFontColor: '#444',
    responsive: true,
    scaleStartValue: 0
  };

  var authorNames = ['Иван Вазов', 'Вера Мутафчиева', 'Блага Димитрова', 'Емилиян Станев', 'Димитър Димов', 'Елин Пелин', 'Йордан Радичков', 'Йордан Йовков', 'Димитър Талев'];
  authorNames.reverse();
  var lemmasIgnoreMissing = [12858, 13071, 13240, 11956, 11811, 11093, 10737, 9916, 9282];
  lemmasIgnoreMissing.reverse();

  var totalUniqueChart = new Chart(lemmasIgnoreMissingCtx).Bar({
    labels: authorNames,
    datasets: [{
      fillColor: "rgba(151,187,205,0.8)",
      data: lemmasIgnoreMissing
    }]
  }, options);
</script>

В сравнение с предишните резултати, тук числата са доста по-малки - за пример, Емилиян Станев е използвал близо 28 000 уникални думи, но само 12 000 уникални леми. Това е причинено от разгледаната в предходната статия особеност на българския език - **една лема може да има множество различни форми според употребата си**. За разлика от резултатите от анализа на уникални думи, изглежда, че Вазов не е използвал най-много уникални леми. На пръв поглед Вера Мутафчиева и Блага Димитрова са използвали малко повече различни леми от него.

Несъотвествието между броя уникални думи и уникални леми би могло да се случи например, ако Блага Димитрова е писала само в сегашно време и мъжки род. Тогава броят уникални думи, които тя е използвала, ще е много близък до броя уникални леми, тъй като няма да има разнообразие във формите на думите. Съответно, ако Вазов е използвал същите леми, но в повече родове и числа, той ще излезе по-напред при сравнението по брой уникални думи.

В случая обаче това несъотвествие е причинено от алгоритъма - както отбелязахме и преди, Вазов е използвал множество архаични и народни думи, които дори по негово време не са били в официалните речници, а какво остава за един съвремен речник. Поради тази особеност си струва да повторим анализа с малка модификация - ако някоя дума не се среща в речника, тя се брои за уникална лема. Така за лема на **пивопийци** ще приемем самата дума, вместо единственото число **пивопиец**. Разбира се, това отново не е перфектно, тъй като **пивопийци** и **пивопийците** ще се преброят като две различни думи - а първоначалната цел беше да избегнем точно това.

<canvas id="lemmasAddMissing" width="550" height="400"></canvas>
<script type="text/javascript">
  var lemmasAddMissingCtx = document.getElementById('lemmasAddMissing').getContext('2d');
  var options = {
    scaleLabel: " <%= value %>",
    scaleShowVerticalLines: false,
    barValueSpacing: 10,
    scaleFontStyle: 'bold',
    scaleFontSize: 14,
    scaleFontColor: '#444',
    responsive: true,
    scaleStartValue: 0
  };

  var authorNames = ['Иван Вазов', 'Вера Мутафчиева', 'Блага Димитрова', 'Емилиян Станев', 'Димитър Димов', 'Елин Пелин', 'Йордан Радичков', 'Йордан Йовков', 'Димитър Талев'];
  authorNames.reverse();
  var lemmasAddMissing = [17856, 15295, 14756, 14022, 13083, 13516, 12886, 12117, 11321];
  lemmasAddMissing.reverse();

  var totalUniqueChart = new Chart(lemmasAddMissingCtx).Bar({
    labels: authorNames,
    datasets: [{
      fillColor: "rgba(151,187,205,0.8)",
      data: lemmasAddMissing
    }]
  }, options);
</script>

Тази графика повече наподобява резултатите от предишната статия. Основната разлика е, че Елин Пелин и Димитър Димов си разменят петото и шестото място.

Горното изложение хвърля малко светлина върху възможностите за преброяване на различните думи. Разглеждането на уникални думи е лесно за разбиране и обяснение и има ясни недостатъци. Лематизацията и стеминга са нетривиални за реализация, по-сложни за описание и водят до трудни за забелязване неточности, когато са използвани за целта на такова изследване. Това обуславя и отхвърлянето им от първоначалния анализ.

Друг интересен въпрос е защо разглеждаме фиксиран брой думи. Една алтернатива е да преброим колко са уникалните думи в творчеството на даден автор и да видим каква част са те от цялото му творчество. Димитър Димов например е използвал около 410 000 думи в трите си романа (“Поручик Бенц”, “Осъдени души” и “Тютюн”). Сред тях има 39 000 различни. Можем да дефинираме “**оценка за уникалност**” като **броя уникални думи, разделен на всички думи** в творчеството на автора - за Димов това е 39 000 / 410 000 = 9.5%. Тази оценка можем да пресметнем за останалите писатели и просто да определим кой е с най-добър резултат - по-голяма оценка означава повече уникални думи - съответно и по-добро представяне в текущото сравнение.

С този подход има един сериозен проблем. Ако сътворим изречение с десет думи, е
напълно възможно всичките десет да са уникални - така бихме му дали оценка от
100%. Ако обаче продължим да пишем, ще става все по-трудно да използваме само
думи, които не сме използвали преди. Така когато изпишем 1000 думи, ще сме
използвали може би 600 различни и ще имаме оценка за уникалност 60% - въпреки
че сме използвали 6 пъти по-богат речник, отколкото в началото, оценката ни е
значително по-ниска. Затова не е коректно да сравняваме двама автори по тази
оценка, ако единият е написал един милион думи, а другият - 100 000.

На следващата графика е показана оценката за уникалност за разгледаните автори в зависимост от броя анализирани думи. Уникалните думи се дефинират по начина от предишната статия.

<canvas id="uniqueCoef" width="550" height="600"></canvas>
<script type="text/javascript">
  var uniqueCoefCtx = document.getElementById('uniqueCoef').getContext('2d');
  var options = {
    scaleLabel: " <%= ~~(value * 100) %> %",
    scaleShowVerticalLines: false,
    barValueSpacing: 10,
    scaleFontStyle: 'bold',
    scaleFontSize: 14,
    scaleFontColor: '#444',
    responsive: true,
    scaleOverride: true,
    scaleStartValue: 0,
    scaleStepWidth: 0.02,
    scaleSteps: 11,
    datasetFill: false,
    multiTooltipTemplate: "<%= datasetLabel %> - <%= ~~(value * 100) %> %"
  };

  var authorNames = ['Иван Вазов', 'Вера Мутафчиева', 'Блага Димитрова', 'Емилиян Станев', 'Димитър Димов', 'Елин Пелин', 'Йордан Радичков', 'Йордан Йовков', 'Димитър Талев'];
  authorNames.reverse();

  var colors = ['rgba(151,187,205,1)', 'rgba(121,167,245,1)', 'rgba(181,137,205,1)', 'rgba(251,187,205,1)', 'rgba(151,237,205,1)', 'rgba(121,207,205,1)', 'rgba(51,187,235,1)', 'rgba(151,87,175,1)', 'rgba(191,67,55,1)'];
  colors.reverse();

  var CORPUS_SIZE_DELTA = 100000;
  var maxCorpusSize = Math.max.apply(null, unique.total);
  var uniquePerCorpusSize = [];
  for (var i = 0; i < authorNames.length; ++i) {
    var cur = [];
    for (var corpusSize = CORPUS_SIZE_DELTA; corpusSize <= unique.total[i]; corpusSize += CORPUS_SIZE_DELTA) {
      cur.push(unique[corpusSize][i] / corpusSize);
    }
    uniquePerCorpusSize.push({
      label: authorNames[i],
      data: cur,
      strokeColor: colors[i],
      pointColor: colors[i],
    });
  }
  uniquePerCorpusSize.reverse();

  var labels = [];
  for (var corpusSize = CORPUS_SIZE_DELTA; corpusSize <= maxCorpusSize; corpusSize += CORPUS_SIZE_DELTA) {
    labels.push(corpusSize);
  }

  var data = {
      labels: labels,
      datasets: uniquePerCorpusSize
  };

  var chart = new Chart(uniqueCoefCtx).Line(data, options);
</script>

Ако разгледаме оценките за уникалност за фиксиран брой анализирани думи - да кажем 200 000, ще получим подобни резултати като от първоначалното изследване - ако преди някой автор е имал 25 000 уникални думи, в случая ще има 25 000, разделено на 200 000. Това не оказва влияние на реда. Ако обаче разгледаме оценката за уникалност на всеки автор за броя думи, които общо сме анализирали за него, подредбата би се променила значително. Например Вазов има само 10% уникални думи от 500-те хиляди анализирани. Това би го поставило след 4 други автора. Всеки от тях обаче е написал по-малко думи от Вазов (поне в разгледаните произведения). Както обсъдихме, това дава преднина на авторите с по-скромно по обем творчество - и затова не би могло да е основа за справедливо сравнение.

Във всяко изследване трябва да се взимат решения. Обикновено те целят да създадат най-добрите възможни условия, но понякога са обусловени от технически или други ограничения. В такива случаи е трудно да се подобри изследването, но съответните решения се оповестяват, за да е ясно какви неточности може да са допуснати и защо. Например текущият анализ не разглежда подсъзнателните решения, взети от автора, тъй като методите на съвременната психология все още не позволяват това. :)

http://people.ischool.berkeley.edu/~nakov//selected_papers_list/nakov_BLRT_BulStem.pdf
https://github.com/Glamdring/language-tools-bg/blob/master/src/main/java/bg/bozho/ikratko/other/NewsSitesVocabulary.java - Основата на използвания алгоритъм за лематизация, написана от Божидар Божанов.


